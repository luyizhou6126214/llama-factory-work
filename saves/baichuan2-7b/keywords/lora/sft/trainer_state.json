{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.973333333333334,
  "eval_steps": 500,
  "global_step": 336,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 6.25765323638916,
      "learning_rate": 1.9957163909297253e-05,
      "loss": 1.6744,
      "step": 10
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 2.8312528133392334,
      "learning_rate": 1.982729621877433e-05,
      "loss": 0.723,
      "step": 20
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.3923523426055908,
      "learning_rate": 1.9611527733473416e-05,
      "loss": 0.4259,
      "step": 30
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 1.4150493144989014,
      "learning_rate": 1.931174449447466e-05,
      "loss": 0.3438,
      "step": 40
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.7480544447898865,
      "learning_rate": 1.893056691922736e-05,
      "loss": 0.2302,
      "step": 50
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.7762343287467957,
      "learning_rate": 1.847132689637477e-05,
      "loss": 0.1699,
      "step": 60
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 0.677568793296814,
      "learning_rate": 1.793803866158037e-05,
      "loss": 0.2413,
      "step": 70
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 1.1041457653045654,
      "learning_rate": 1.7335363708931116e-05,
      "loss": 0.1463,
      "step": 80
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.3560107946395874,
      "learning_rate": 1.6668570044628597e-05,
      "loss": 0.1531,
      "step": 90
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 1.807845950126648,
      "learning_rate": 1.594348613913319e-05,
      "loss": 0.1934,
      "step": 100
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 1.1016676425933838,
      "learning_rate": 1.5166449980267403e-05,
      "loss": 0.2168,
      "step": 110
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 0.7247313261032104,
      "learning_rate": 1.4344253672607299e-05,
      "loss": 0.1399,
      "step": 120
    },
    {
      "epoch": 2.311111111111111,
      "grad_norm": 1.3249523639678955,
      "learning_rate": 1.3484084067420936e-05,
      "loss": 0.181,
      "step": 130
    },
    {
      "epoch": 2.488888888888889,
      "grad_norm": 1.3777378797531128,
      "learning_rate": 1.259345994211e-05,
      "loss": 0.1038,
      "step": 140
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.9464147686958313,
      "learning_rate": 1.1680166278271618e-05,
      "loss": 0.1233,
      "step": 150
    },
    {
      "epoch": 2.8444444444444446,
      "grad_norm": 1.3159326314926147,
      "learning_rate": 1.075218621285851e-05,
      "loss": 0.1125,
      "step": 160
    },
    {
      "epoch": 3.022222222222222,
      "grad_norm": 0.7387247681617737,
      "learning_rate": 9.817631257255142e-06,
      "loss": 0.1413,
      "step": 170
    },
    {
      "epoch": 3.2,
      "grad_norm": 1.3420236110687256,
      "learning_rate": 8.884670394227768e-06,
      "loss": 0.131,
      "step": 180
    },
    {
      "epoch": 3.3777777777777778,
      "grad_norm": 1.0595182180404663,
      "learning_rate": 7.96145867251479e-06,
      "loss": 0.0846,
      "step": 190
    },
    {
      "epoch": 3.5555555555555554,
      "grad_norm": 1.2241945266723633,
      "learning_rate": 7.056065923215023e-06,
      "loss": 0.0931,
      "step": 200
    },
    {
      "epoch": 3.7333333333333334,
      "grad_norm": 0.5847854018211365,
      "learning_rate": 6.17640622106679e-06,
      "loss": 0.128,
      "step": 210
    },
    {
      "epoch": 3.911111111111111,
      "grad_norm": 2.743441104888916,
      "learning_rate": 5.330168707199711e-06,
      "loss": 0.1269,
      "step": 220
    },
    {
      "epoch": 4.088888888888889,
      "grad_norm": 1.794303059577942,
      "learning_rate": 4.5247503780402566e-06,
      "loss": 0.1002,
      "step": 230
    },
    {
      "epoch": 4.266666666666667,
      "grad_norm": 0.9490655660629272,
      "learning_rate": 3.7671914278660116e-06,
      "loss": 0.071,
      "step": 240
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 1.1290355920791626,
      "learning_rate": 3.064113710181996e-06,
      "loss": 0.1271,
      "step": 250
    },
    {
      "epoch": 4.622222222222222,
      "grad_norm": 0.9406759738922119,
      "learning_rate": 2.421662855830638e-06,
      "loss": 0.0981,
      "step": 260
    },
    {
      "epoch": 4.8,
      "grad_norm": 1.3886480331420898,
      "learning_rate": 1.8454545537833447e-06,
      "loss": 0.1084,
      "step": 270
    },
    {
      "epoch": 4.977777777777778,
      "grad_norm": 1.6368093490600586,
      "learning_rate": 1.3405254641754861e-06,
      "loss": 0.0692,
      "step": 280
    },
    {
      "epoch": 5.155555555555556,
      "grad_norm": 0.892700731754303,
      "learning_rate": 9.112891926558854e-07,
      "loss": 0.0789,
      "step": 290
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 0.23687174916267395,
      "learning_rate": 5.614977108808595e-07,
      "loss": 0.058,
      "step": 300
    },
    {
      "epoch": 5.511111111111111,
      "grad_norm": 1.4085347652435303,
      "learning_rate": 2.9420856037781667e-07,
      "loss": 0.1199,
      "step": 310
    },
    {
      "epoch": 5.688888888888889,
      "grad_norm": 1.1735767126083374,
      "learning_rate": 1.1175812645077388e-07,
      "loss": 0.0746,
      "step": 320
    },
    {
      "epoch": 5.866666666666667,
      "grad_norm": 1.9529242515563965,
      "learning_rate": 1.574121574165921e-08,
      "loss": 0.1347,
      "step": 330
    },
    {
      "epoch": 5.973333333333334,
      "step": 336,
      "total_flos": 1.8305456759832576e+16,
      "train_loss": 0.20740249424818016,
      "train_runtime": 706.4849,
      "train_samples_per_second": 7.643,
      "train_steps_per_second": 0.476
    }
  ],
  "logging_steps": 10,
  "max_steps": 336,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.8305456759832576e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
